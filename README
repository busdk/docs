# BuSDK Design Document

Modular CLI-First Accounting Toolkit (CSV + Frictionless Data + Git)

## Purpose and scope

BuSDK (Business Unit Software Development Kit), formerly known as Bus, is a modular, command-line-first toolkit for small-business accounting and bookkeeping. It is intentionally designed for longevity, clarity, and extensibility: all financial data is stored in transparent, human-readable text files and tracked in a Git repository so that the full history of bookkeeping activity remains auditable and reproducible. The primary target user is a sole entrepreneur who wants to automate their own bookkeeping in areas such as ledger entries, invoicing, VAT (ALV) handling, bank transaction imports, PDF invoice generation, and budgeting, while keeping the system sufficiently structured and standardized to support future AI-assisted automation without making AI a dependency.

This document defines BuSDK’s goals, system architecture, data formats and storage conventions, CLI tooling and workflow expectations, extensibility model, canonical data directory layout, and an end-to-end example workflow illustrating day-to-day use.

A visual identity is assumed to exist for produced documents and outputs, including a BuSDK logo. The logo is explicitly expected to appear on generated artifacts such as invoices.

## Design goals and requirements

BuSDK is built to reflect the “small tools that do one thing well” philosophy of Unix-style composability, where independent programs cooperate through simple, universal interfaces and predictable conventions. ([catb.org][1]) In BuSDK, the universal interface is not a pipe stream but the shared, versioned dataset: CSV resources with stable schemas.

The system is modular from the start. Each major feature area is implemented as an independent, small tool or service that interacts through shared data rather than tight coupling. Ledger, invoicing, tax reporting, bank import, budgeting, and document generation are intended to be independently developed, tested, and deployed in isolation. Modules communicate via the common data repository rather than through direct function calls or internal APIs, increasing robustness, reducing integration risk, and supporting parallel development.

The data format is deliberately plain-text and longevity-oriented. All business and accounting data is stored in CSV using UTF-8 text so that it remains accessible decades into the future without dependence on proprietary software. CSV is expected to remain readable and usable because it is ubiquitous, standardized in practice, and supported across tools and operating systems; guidance on “sustainable formats” emphasizes widespread support and self-describing characteristics as key factors in long-term accessibility. ([TransAccess][2]) BuSDK therefore treats its dataset as a durable business record, not as the private internal state of a single application.

Plain CSV is paired with structured schemas. Each dataset adheres to Frictionless Data’s Table Schema, a JSON-based schema specification for tabular data. Table Schema provides field metadata including names, data types, and constraints, enabling automatic validation and consistent processing across modules while keeping the underlying data easily inspectable and editable. ([Frictionless Data][3]) This schema-driven approach makes the data self-describing and ensures different modules can agree on the same structure without sharing code.

Git is the canonical, append-only source of truth. The Git repository containing the CSV resources and schemas is treated as the system’s database of record. Every change to any CSV—adding transactions, adding an account, recording an invoice, correcting an error—is captured as a commit that contributes to an immutable history of modifications. The underlying Git model stores objects addressed by cryptographic hashes, with commit objects referencing their parent commits, forming a hash-linked history. ([Git][4]) BuSDK leverages this structure to maintain a tamper-evident audit log of bookkeeping activity, consistent with the accounting requirement that historical records are preserved and corrections are explicit rather than silently destructive.

Double-entry ledger accounting is a core requirement. The ledger follows double-entry bookkeeping principles: each financial transaction is recorded with equal and opposite debit and credit entries affecting two or more accounts. This provides a built-in checksum, supports accrual-based accounting concepts (including receivables and payables, not only cash), and enforces the accounting equation that underpins reliable statements. ([docs.mypocketcfo.com][5])

BuSDK aims to provide comprehensive small-business features through dedicated modules. The initial scope includes a general ledger and chart of accounts; invoicing for sales and purchases with status tracking and linkage to ledger entries; Finnish VAT (ALV) classification and reporting for periods and rates; bank transaction import from common online banking exports with user mapping and categorization; generation of professional PDF invoices, preferably in a long-term archival profile such as PDF/A for sustainability; and budgeting with budget-versus-actual reporting. PDF/A is specifically intended for long-term preservation use cases and is defined as an ISO-standardized profile designed for archives. ([The Library of Congress][6])

The system is CLI-first and human-friendly. Every function is accessible via CLI commands designed to be intuitive and consistent, and suitable for SSH-based work, automation, and future API exposure. Where useful, commands should support machine-readable output formats (CSV or JSON) in addition to human-readable output, enabling scripts and later agentic integrations.

Auditability and append-only discipline are non-negotiable. BuSDK enforces an append-only approach to financial records. Once a transaction is recorded and committed, it is not erased or rewritten; corrections are performed through explicit new entries such as reversals, and metadata changes are tracked through commits. Git history ensures that even manual edits become visible as diffs, but user-facing tools are expected to discourage or disallow destructive edits and to prefer explicit corrective actions.

Extensibility is a first-class goal. The architecture must remain simple enough that a single developer can implement a new module over a weekend using common libraries. The data contracts (CSV + schemas) are the shared interface so that modules can be written in different programming languages and still interoperate. New business capabilities—inventory, payroll, specialized reports—should be addable by defining new datasets and tools without requiring a rewrite of the core.

AI-readiness is a design objective, not a dependency. BuSDK must remain fully functional without AI. At the same time, its structured, standardized dataset is intentionally designed to make AI-assisted classification, reconciliation, and anomaly detection easier and safer, because proposed changes can be represented as patches and reviewed through Git workflows before acceptance. Claims that AI can reduce manual bookkeeping effort through faster categorization and reconciliation reflect current industry positioning and should be treated as optional augmentation. ([Uplinq][7])

## System architecture

### Architectural overview

BuSDK is a collection of loosely coupled modules centered around a single Git-backed data repository. It intentionally avoids a monolithic application design and instead follows a “micro-tool” architecture: each feature area is implemented as an independent CLI tool (or service) that reads and writes a shared dataset. Modules coordinate by sharing data and by relying on the Git history as a durable audit trail, rather than by calling each other’s internal APIs.

This design mirrors the practical benefits of Unix composability in modern toolchains, where interoperability arises from stable, simple interfaces and predictable conventions. ([catb.org][1]) In BuSDK, the stable interface is the repository: a set of CSV resources governed by Frictionless schemas and organized in a consistent directory structure.

### Core components

The data store is a Git repository containing all business records in CSV form plus their schemas. Git is not used merely for source control; it is treated as the database. Modules treat the Git-managed files as the single source of truth. When reading data, a module operates on the current working state of the repository. When writing data, it modifies the relevant CSV files and produces a commit describing the operation. Git provides an immutable log of changes, revert capability, and branching for experimentation or review. The Git internals model—content-addressed objects and parent-linked commits—provides a cryptographically chained record that supports tamper-evidence when histories are shared and anchor points are agreed. ([Git][4])

Modules are independent tools or services. Each functional area is a module: ledger, invoice, bank import, VAT, budget, and related features. Modules encapsulate their domain logic and do not call each other’s functions directly. Integration occurs through shared datasets. When the invoice module needs to produce ledger impact, it writes journal entries into the journal dataset through the same data layer conventions as the ledger module, rather than invoking ledger APIs. This keeps modules loosely coupled and allows modules to be implemented in different languages. For example, a Python component could generate PDFs while a Go component enforces ledger integrity, both interoperating through CSV files and Git commits.

The CLI is the primary interface. Commands are expected to perform a controlled read-modify-write cycle: load the necessary resources from the repository, validate requested changes against schema and business rules, apply the operation, write the updated files, then commit the change with a descriptive message. For example, a journal command such as:

```bash
busdk journal add --date 2026-01-15 --debit Cash --credit Sales --amount 500 --desc "Invoice 1001 payment"
```

is expected to append new ledger rows to the journal file and commit with a message that narrates what happened, such as “Add journal entry: 2026-01-15 Invoice 1001 payment.” This makes the CLI the gatekeeper of data integrity and reduces the risk of user error compared with manual CSV editing.

A shared validation layer is foundational. Each module relies on schema validation and logical validation before accepting a mutation. Schema validation checks types and constraints such as required fields, formats, keys, and referential integrity. Logical validation enforces accounting rules such as balanced double-entry transactions and consistency of invoice totals. Schema compliance is standardized via Table Schema. ([Frictionless Data][3]) Logical validation is implemented in module logic, particularly where cross-row invariants are required (for example, “sum of debits equals sum of credits for a transaction group”).

### Append-only discipline and security model

Historical financial data is append-only. Modules add lines, mark records inactive where appropriate, and avoid destructive updates. If scrubbing sensitive data is ever required, it is handled via an explicit redaction commit that flags the redaction rather than silently excising history.

In single-user operation on a local machine, security is primarily OS-level control. In collaborative scenarios, Git permissions and workflows are used to control who can propose and approve changes. Branch protections, pull requests, and reviews can enforce separation of duties such as preparer-versus-approver. The architecture is designed so these workflows are natural extensions of the Git data store rather than special cases.

## Data format and storage

### CSV conventions

All BuSDK data is stored as CSV text files with a header row and one record per row. Conventions prioritize compatibility: UTF-8 encoding; comma delimiters; quoting for fields containing commas or newlines; ISO date formats (YYYY-MM-DD) for date fields; and predictable numeric formats for monetary values. The intended result is that the dataset remains usable in both text editors and common spreadsheet tools, supporting the long-term accessibility goals associated with sustainable formats guidance. ([TransAccess][2])

### Frictionless Table Schema as the contract

Each CSV has a corresponding JSON Table Schema that declares fields, types, constraints, and structural metadata. Table Schema supports declaring required fields, minimums, patterns, primary keys, and foreign keys. The schema functions simultaneously as documentation, as automated validation input, and as future-proofing mechanism when schemas evolve across time. ([Frictionless Data][3])

Because Table Schema is standardized, modules can share a single interpretation of datasets even when implemented in different languages. Validation can be performed by integrating Frictionless-compatible tooling or libraries, but BuSDK’s architectural requirement is that validation behavior is consistent across modules regardless of implementation language.

### Data Package organization

BuSDK may optionally adopt a Frictionless Data Package (typically a `datapackage.json`) to provide a repository-wide manifest of resources and their schemas. A Data Package descriptor lists resources, their paths, and their schema references, enabling whole-repository validation and standardized publication or interchange patterns. ([specs.frictionlessdata.io][8]) Even without a descriptor, the directory structure is designed to be discoverable and navigable, but the Data Package option improves automation and interoperability.

### Schema evolution and migration

BuSDK assumes schemas will evolve as a business evolves. Schema changes are versioned in Git and may include a schema version indicator so tooling can identify the schema version at a given commit. When adding fields, BuSDK may provide migration commands that insert default values across historical rows, or it may treat missing fields in older rows as null/default during reporting. Large structural changes such as splitting a file or renaming a field are acceptable so long as migrations are transparent and recorded in Git history.

### Append-only updates and soft deletion

For critical ledgers such as the journal, BuSDK enforces that new transactions are appended as new rows and that corrections are represented as new records such as reversing entries, not silent in-place edits. Where record removal semantics are required (for example, voiding an invoice), BuSDK prefers soft deletion via an “active” boolean or explicit status field rather than removing rows from history. Git history provides a backstop by exposing deletions as diffs, but user-facing tools are expected to discourage destructive edits.

### Scaling over decades

CSV is viable long-term if proactively managed. To keep repositories performant and diffs focused, BuSDK supports splitting data into multiple files by time period or category. A typical strategy is to segment journal data by year, such as `journal_2025.csv` and `journal_2026.csv`, instead of allowing a single file to grow indefinitely. This reduces the size and complexity of day-to-day diffs, keeps Git operations snappy, and aligns with the practical expectation that even large datasets can remain manageable when partitioned. Older data can be archived by tagging year-end commits, and where desired, by removing old-year files from active branches while retaining them in history for retrieval.

## CLI tooling and workflow

### Command structure and discoverability

BuSDK is CLI-first. Commands are organized by module and generally follow a verb-noun structure. Examples include `busdk accounts add` for chart-of-accounts changes; `busdk journal record` (and, in some contexts, `busdk journal add`) for ledger entry creation; `busdk invoice create` for invoice creation; `busdk invoice generate-pdf` or `busdk invoice pdf` for invoice document generation; `busdk vat report` for VAT summaries; and `busdk budget set` or `busdk budget add` for budgeting operations. The top-level `busdk` command or `busdk help` is expected to list available modules and commands, while module-level help such as `busdk journal --help` provides command usage details.

### Interactive use and scripting parity

Every command must be usable interactively and non-interactively. Interactive prompts are used when the user omits parameters, enabling a guided experience. Non-interactive flags and arguments must allow full scripting and automation. This includes workflows such as nightly cron-driven bank imports or scripted ledger entries produced by external systems.

### Validation and safety checks

Before any data mutation, the CLI performs schema validation and logical validation. Schema validation ensures type correctness and referential integrity. Logical validation enforces business rules such as existing account references, balanced debits and credits for transactions, invoice totals matching line items, and VAT classification completeness when generating VAT reports. If errors are found, the command fails with a clear diagnostic and refuses to commit invalid data.

### Automated Git commits per operation

A distinctive behavior of BuSDK is integrating Git into the default workflow. After a command successfully updates data, the CLI stages and commits changes with templated, descriptive messages so the user does not need to manually perform `git add` and `git commit` for routine bookkeeping. For example:

```bash
busdk accounts add --code 3000 --name "Consulting Income" --type Income
```

is expected to append a new account row to `accounts.csv` and commit with a message such as “Add account 3000 Consulting Income.”

The default model is “one commit per high-level operation” to maximize audit clarity and align with append-only discipline. BuSDK may also support batching operations into a single commit either through explicit batch modes or by allowing auto-commit to be disabled so the user can commit manually after a series of commands.

### Reporting and query commands

In addition to mutating commands, BuSDK provides read-only query and reporting commands that compute balances, statuses, and summaries from the CSV resources. Examples include `busdk accounts list`; `busdk journal balance --as-of 2026-03-31`; `busdk invoice list --status unpaid`; `busdk vat report Q1-2026`; and `busdk budget report --period 2026`. Output is expected to be human-readable and may include tabular terminal formatting; where relevant, machine-readable output options should exist for integration with scripts and downstream analysis.

### Extensible CLI surface and API parity

As new modules are added, they introduce new subcommands without breaking existing behavior. The CLI should correspond to underlying library functions where feasible so that future API layers can wrap the same logic. The eventual architecture anticipates an “API parity” model where CLI operations map cleanly to callable functions or REST endpoints.

### Error handling, dry-run, and diagnostics

The CLI is expected to fail gracefully and provide clear error messages. If Git is not available or the repository is not initialized, the tool should detect this and instruct the user to run an initialization command or to operate within the correct directory. Merge conflicts caused by concurrent edits or manual file modifications must be detected and surfaced, with guidance for resolution. A `--dry-run` flag should be available to preview changes without committing. Optional logging should provide visibility into validation steps and Git commands executed, supporting trust and diagnosability.

## Integration and future interfaces

Although CLI is the initial interface, the architecture is designed for future APIs, dashboards, or external integrations. Because modules already parse inputs, validate, and produce outputs, they can be wrapped by a RESTful server or web interface without moving business logic into a monolith. The Git repository and CSV resources are treated as a contract that any interface can operate on, including static reporting sites and BI tools that read CSV directly.

External systems can integrate by exchanging CSV resources or by operating on the Git repository itself. Examples include a web store exporting daily sales as CSV for invoice import, or a CRM integration that triggers creation of customer records via a commit or webhook-driven automation. The design aims to prevent vendor lock-in by relying on open, widely supported formats.

## Extensibility model

### Plug-in modules via new datasets

BuSDK supports adding modules by defining new datasets and schemas and implementing tooling that reads and writes them. A payroll module is a canonical example: a `payroll/` directory could contain `employees.csv` and `payruns.csv` plus schemas, and a CLI command such as `busdk payroll run --month July-2026` could generate salary-related ledger entries by appending to the journal dataset. This extension does not require modifications to existing modules so long as it adheres to established schemas and references valid accounts.

### Event hooks and automation

Although BuSDK is CLI-driven rather than event-driven by default, the architecture supports automation via Git hooks or file watchers. Post-commit hooks can trigger secondary actions such as generating PDFs when invoices are created, emailing invoices, or notifying the owner for review when large transactions are recorded. BuSDK intends to document patterns for such automation and may later provide a lightweight plugin system where modules can subscribe to repository events such as “new invoice” or “new journal entry.”

### AI and external service integration

AI integration is treated as an optional module layer. An AI assistant can read repository data to identify anomalies and can propose changes as commits or branches for human review. This creates a reviewable workflow where the user remains in control and AI suggestions become auditable artifacts. Industry narratives emphasize that AI can accelerate bookkeeping by classifying and reconciling transactions quickly; BuSDK’s structured data and Git-based review model is designed to enable this safely rather than implicitly trusting black-box automation. ([Uplinq][7])

### One-developer contributions and ecosystem

BuSDK lowers the barrier for user-written extensions. A user can write small scripts or commands to produce specialized reports such as accounts receivable aging, using only the CSV files and schemas. This encourages an ecosystem of shareable custom modules and report scripts, similar in spirit to communities around CLI-based accounting tools.

### Governance of core schemas

As modularity increases, schema divergence becomes a risk. BuSDK treats core schemas—particularly accounts and journal—as public APIs that require lightweight governance. Schema changes are expected to preserve backward compatibility or provide explicit migrations. New modules should reuse existing keys and fields where appropriate and should integrate financial value changes through the ledger to preserve a comprehensive financial picture. Cross-links such as invoice IDs referencing journal transaction IDs are encouraged for traceability.

## Data directory layout

BuSDK organizes data in a transparent directory structure at the repository root. The structure is designed for human discoverability while remaining machine-validated through schemas.

The accounts area holds the chart of accounts and related reference data. `accounts.csv` contains ledger accounts with fields such as account code/number, name, category/type (Asset, Liability, Equity, Income, Expense), optional description, and possibly hierarchical relationships through parent accounts. A corresponding schema such as `schemas/accounts.schema.json` enforces uniqueness and valid types. Additional reference datasets such as `contacts.csv` or `entities.csv` may exist if customer and vendor identity tracking is needed beyond invoice free-text fields.

The journal area contains general ledger transactions. A `journal.csv` (or segmented files like `journal_2025.csv`, `journal_2026.csv`) records ledger entries. The preferred representation is “one line per entry” rather than “one line per transaction,” because multi-line transactions require flexible entry counts. A representative schema includes fields such as transaction ID, date, account reference, debit, credit, currency, amount representation strategy (separate debit/credit fields versus a signed amount), and description. Schema validation enforces field correctness; balanced transaction invariants are enforced by module logic.

The invoices area contains invoicing data. Sales and purchase invoices are separated for clarity. A typical structure includes `sales_invoices.csv` for invoice headers and `sales_invoice_lines.csv` for line items, and similarly `purchase_invoices.csv` and `purchase_invoice_lines.csv` for purchases. Header records include invoice number, date, customer or supplier identifier, due date, total amount, VAT amount, and status such as unpaid or paid. Line items include invoice number as a foreign key, description, quantity, unit price, line total, VAT rate, and ledger account mapping. Schemas enforce referential integrity and numeric constraints such as non-negative totals. A combined `invoices.csv` with a type column is possible, but separation is preferred to simplify VAT handling differences.

An optional `invoices/pdf/` area stores generated invoice PDFs named by invoice number such as `INV-1001.pdf`. Storing PDFs in Git is supported for completeness even though diffs for binaries are not meaningful; repository size concerns may cause users to store PDFs outside Git, but the default encourages “everything together” for audit completeness. Where long-term preservation is desired, PDF/A should be used for generated invoices. ([The Library of Congress][6])

An optional VAT area can hold VAT reference data and filed summaries. VAT reports can generally be generated from invoices and journal entries, but reference datasets such as `vat_rates.csv` may be useful to track VAT percentages over time, and filed summaries such as `vat_return_2026-Q1.csv` may be generated and committed to preserve what was submitted.

A budgeting area holds planned budgets in datasets such as `budgets.csv`, where each row typically represents a budgeted amount by account and period using fields like fiscal year, account, period identifier (year-month or quarter), and budget amount. Alternative pivoted formats are possible but less “CSV-friendly” in terms of schema validation and diff behavior, so the row-based form is preferred.

A schemas area such as `schemas/` holds Table Schema JSON files for each dataset. Optionally, a `datapackage.json` manifest may be placed at the repository root to bind resources and schemas into a standardized Frictionless Data Package.

A minimal example layout is:

```text
my-business-books/
  README.md
  datapackage.json
  accounts/
    accounts.csv
    contacts.csv
  journal/
    journal_2026.csv
  invoices/
    sales_invoices.csv
    sales_invoice_lines.csv
    purchase_invoices.csv
    purchase_invoice_lines.csv
    pdf/
      INV-1001.pdf
  vat/
    vat_rates.csv
    vat_return_2026Q1.csv
  budget/
    budgets.csv
  schemas/
    accounts.schema.json
    journal.schema.json
    sales_invoices.schema.json
    sales_invoice_lines.schema.json
    purchase_invoices.schema.json
    purchase_invoice_lines.schema.json
    budgets.schema.json
    vat_rates.schema.json
```

The repository-level README is expected to document structure, workflows, and conventions so that a future user (including the same user years later) can understand how to interpret the dataset and how to operate the tools.

## Example end-to-end workflow

Consider Alice, a freelance consultant using BuSDK for her business.

She begins by initializing a new repository. Running `busdk init` creates the directory structure, adds initial schema files, and performs `git init`. It may create a default chart of accounts template and commit the initial state with a message such as “Initialize BuSDK repository.”

She configures her chart of accounts by adding accounts via CLI. For example, she adds “Cash” (an Asset account), “Accounts Receivable” (Asset), “Consulting Revenue” (Income), “VAT Payable” (Liability), and common expense accounts. Each addition updates `accounts.csv`, validates schema rules such as uniqueness, then commits an audit-friendly message.

When she buys a new laptop for work, she records the transaction as a double-entry journal record that credits Cash and debits an equipment-related expense or asset account. She runs:

```bash
busdk journal record --date 2026-01-10 \
--desc "Bought new laptop" \
--debit "Office Equipment"=2500 \
--credit "Cash"=2500
```

The command generates two ledger rows in `journal/journal_2026.csv`, linking them with a shared transaction ID. The CLI ensures the debits equal the credits and rejects unknown account names. On success, it commits with a message such as “Record transaction: 2026-01-10 Bought new laptop €2,500.” This makes it difficult to accidentally record only half of a double-entry transaction, supporting reliable bookkeeping. ([docs.mypocketcfo.com][5])

When Alice needs to bill a client, she issues a sales invoice. She runs `busdk invoice create --type sales` without providing all fields, and the tool enters interactive mode. It requests the invoice number (such as “INV-1001,” with optional auto-generation), invoice date (such as 2026-01-15), customer name (such as “Acme Corp,” optionally selectable from a customer list if maintained), then prompts for line items iteratively. Alice enters a line item for consulting services with a quantity of 10 hours at €100/hour, maps it to her consulting revenue account, and sets VAT rate to 24%. The CLI calculates subtotal €1000, VAT €240, total €1240, and defaults due date to 30 days from invoice date (2026-02-14). After confirmation, the module writes the invoice header to `invoices/sales_invoices.csv`, writes the line item to `invoices/sales_invoice_lines.csv`, generates `invoices/pdf/INV-1001.pdf` with branding and required details, then commits with a message such as “Add sales invoice INV-1001 for €1240 to Acme Corp.”

For integration convenience, the invoice module can also write the corresponding ledger impact automatically by appending journal lines that debit Accounts Receivable €1240, credit Consulting Revenue €1000, and credit VAT Payable €240, optionally tagging the transaction with invoice number for traceability. This integration is accomplished by writing to the shared journal dataset rather than calling ledger internals.

When the customer pays, Alice downloads her bank’s February CSV statement and runs `busdk bank import --file statements/Feb2026.csv`. The tool reads the statement and identifies new transactions. For the €1240 credit from Acme, Alice identifies it as payment for INV-1001 and selects an option to apply it to the invoice. The tool then writes journal entries to debit Cash and credit Accounts Receivable for €1240, updates the invoice status in `sales_invoices.csv` to “Paid,” and records the payment date. For other statement lines such as bank fees or interest, the tool prompts for categorization or matches automatically based on patterns.

If AI assistance is present, classification can be suggested automatically, such as identifying that €1240 matches an open invoice and mapping a €10 bank fee to a bank-fees expense account. The user reviews and approves suggestions before commit, keeping control while benefiting from automation. ([Uplinq][7]) The import results in committed changes, for example with a message like “Import Feb 2026 bank transactions.”

At the end of Q1 2026, Alice files VAT. She runs `busdk vat report --period 2026Q1`. The VAT module scans invoices and/or journal entries from Jan–Mar 2026, separates output VAT on sales from input VAT on purchases, and prints a summary such as:

```text
VAT Summary Q1 2026:
Sales (taxable) total: €1000
Output VAT (@24%): €240
Purchases (tax-deductible) total: €250
Input VAT (@24%): €60
----------------------------
VAT payable: €180
```

The module may also generate a file for record-keeping such as `vat/vat_return_2026Q1.csv` and commit it. When Alice pays €180, she records the payment as a journal transaction (debit VAT Payable, credit Cash) or imports it from the next bank statement.

For budgeting, Alice defines budgets for categories such as office supplies and travel by entering rows into `budget/budgets.csv` via CLI. Later she runs `busdk budget report --year 2026`, which aggregates actual expenses from the ledger and compares them to the budget:

```text
Expense Category     Budget Q1   Actual Q1   Variance
Office Supplies      €500.00     €300.00     €+200.00
Travel               €800.00     €950.00     €-150.00
```

This demonstrates that budgeting is fundamentally a controlled computation over structured CSV, and can be implemented as a small module while remaining integrated and repeatable.

At year end, Alice closes the books. BuSDK may provide a command such as `busdk ledger close-year 2026` to generate closing entries that zero income and expense accounts into retained earnings and roll forward balances. If a built-in command does not exist, the open, schema-defined data allows Alice or her accountant to write a script to perform the close and add it as a custom command, reinforcing extensibility. Closing entries are committed so that the derivation of opening balances for 2027 remains traceable.

Across this workflow, BuSDK emphasizes transparency (CSV and Git history show exactly what happened), control (no silent adjustments; even AI produces reviewable commits), and automation (repeatable commands, integrated document generation, and optional AI-assisted classification).

As the business evolves, BuSDK’s data model can extend. International currency support can be introduced by adding a currency field to relevant schemas and records. If Alice hires an assistant, collaboration can happen via shared Git repositories with pull requests and branch protections. If new taxes or reporting obligations appear, new modules can be added without refactoring the core, because the dataset remains the stable interface.

## References and external foundations

BuSDK’s modular CLI philosophy aligns with the Unix notion of composable tools and clear interfaces, where programs do one thing well and cooperate through simple formats. ([catb.org][1]) The sustainability rationale for storing records in widely supported, documented formats is consistent with guidance on sustainable electronic record formats and long-term accessibility. ([TransAccess][2]) The tabular schema contract is based on Frictionless Data Table Schema and may optionally employ a Frictionless Data Package manifest to bind repository datasets together. ([Frictionless Data][3]) The archival document preference for invoices is consistent with PDF/A’s long-term preservation purpose and conformance constraints. ([The Library of Congress][6]) The tamper-evident audit model relies on Git’s content-addressed object model and parent-linked commit structure, and can be strengthened via shared head anchoring and governance workflows. ([Git][4]) Double-entry and accrual-based accounting expectations are grounded in standard bookkeeping practice; BuSDK’s enforcement model assumes balanced entries and supports receivables/payables workflows. ([docs.mypocketcfo.com][5]) Optional AI augmentation for transaction classification and reconciliation is treated as a non-required module capability aligned with current industry positioning of AI bookkeeping tools. ([Uplinq][7])

[1]: https://www.catb.org/esr/writings/taoup/html/ch01s06.html?utm_source=chatgpt.com "Basics of the Unix Philosophy"
[2]: https://www.tagovcloud.com/2023/06/what-are-sustainable-formats-for-electronic-records-part-1/?utm_source=chatgpt.com "What Are 'Sustainable Formats' For Electronic Records ..."
[3]: https://frictionlessdata.io/specs/table-schema/?utm_source=chatgpt.com "Table Schema | Data Package (v1)"
[4]: https://git-scm.com/book/en/v2/Git-Internals-Git-Objects?utm_source=chatgpt.com "10.2 Git Internals - Git Objects"
[5]: https://docs.mypocketcfo.com/article/131-accrual-based-accounting-method-and-its-double-entry-ledger-system?utm_source=chatgpt.com "Accrual-based accounting method and its double-entry ledger ..."
[6]: https://www.loc.gov/preservation/digital/formats/fdd/fdd000318.shtml?utm_source=chatgpt.com "PDF/A Family, PDF for Long-term Preservation"
[7]: https://www.uplinq.com/post/how-ai-bookkeeping-is-revolutionizing-small-business-accounting?utm_source=chatgpt.com "AI Bookkeeping is Revolutionizing Small Business ..."
[8]: https://specs.frictionlessdata.io/data-package/?utm_source=chatgpt.com "Data Package (v1)"
